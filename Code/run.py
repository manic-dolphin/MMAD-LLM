from llama2.llama import Llama
from planner import Planner

if __name__ == '__main__':
    
    # model = Llama.build(
    #         ckpt_dir='llama2/llama-2-13b/',
    #         tokenizer_path='llama2/tokenizer.model',
    #         max_seq_len=512,
    #         max_batch_size=4,
    #     )
    # planner_model = Planner(model=model)
    # print(planner_model.get_initial_state("15! = ?"))
    print("hello")